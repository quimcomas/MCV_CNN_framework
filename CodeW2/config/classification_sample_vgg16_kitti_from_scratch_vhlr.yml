# Problem type
problem_type                : 'classification' # Option: ['segmentation','classification']

# Model
model_type                  : 'VGG16'   # Options: ['DenseNetFCN', 'FCN8']

### load/store options
resume_experiment           : False
pretrained_model            : 'None'  # 'None': from scratch, 'basic': pretraned from imagenet, 'custom': personal model
input_model_path            : null  # Path and pretrained file to load [None uses experiment path and model name by default]
load_weight_only            : True  # Recomended true, loads only weights and parameters

### Save options
save_weight_only            : True  # Recomended true, stores only weights and parameters
model_name                  : 'VGG16'  # Name of the model to store
output_model_path           : null  # Path to store the model using model_name [None uses the default experiment path]
basic_models_path           : null

# Loss type
loss_type                   : 'cross_entropy_classification' # options: ['cross_entropy_segmentation','focal_segmentation']
normalize_loss              : True

# General parameters

train_samples               : -1
#-1 uses all the data available inside the dataset files
valid_samples               : -1
#-1 uses all the data available inside the dataset files
test_samples                : -1
#-1 uses all the data available inside the dataset files
train_batch_size            : 40
valid_batch_size            : 40
test_batch_size             : 40
train                       : True
validation                  : True
test                        : False # Calculate metrics on test giving the gt
predict_test                : False # True when you want to generate predictions from test, doesn't need gt
predict_path_output         : null # null uses the default output in the experiment folder /predictions

# Image properties
size_image_test             : null
resize_image_train          : !!python/tuple [224, 224]
resize_image_valid          : !!python/tuple [224, 224]
resize_image_test           : !!python/tuple [224, 224]
crop_train                  : null
grayscale                   : False #Use this option to convert to rgb a grascale dataset

# Dataset properties

train_images_txt            : '/home/grupo03/M5/Code/KITTI_txt/train_images.txt'
train_gt_txt                : '/home/grupo03/M5/Code/KITTI_txt/train_gt.txt'
valid_images_txt            : '/home/grupo03/M5/Code/KITTI_txt/valid_images.txt'
valid_gt_txt                : '/home/grupo03/M5/Code/KITTI_txt/valid_gt.txt'
test_images_txt             : '/home/grupo03/M5/Code/KITTI_txt/test_images.txt'
test_gt_txt                 : '/home/grupo03/M5/Code/KITTI_txt/test_gt.txt'

labels                      : !!python/tuple ['Car', 'Cyclist', 'Pedestrian', 'Person_sitting', 'Tram', 'Truck', 'Van', 'background']
map_labels                  : !!python/dict {'Car': 0,'Cyclist': 1,'Pedestrian': 2,'Person_sitting': 3,'Tram': 4,'Truck': 5,'Van': 6,'background': 7}

num_classes                 : 8
shuffle                     : True
void_class                  : 255 #void id or value on the image

# Training
epochs                      : 40 #Max number of epochs
initial_epoch               : 1 #Defines the starting epoch number
valid_samples_epoch         : -1 # Number of validation images used to validate an epoch
is_training                 : True
    ### Optimizer ###
optimizer                   : 'SGD'
momentum1                   : 0.99
momentum2                   : 0.99
learning_rate               : 1.0e-3
learning_rate_bias          : 1.0e-5
weight_decay                : 5.0e-4
    ### Scheduler
scheduler                   : 'MultiStep' #['ReduceLROnPlateau','Step','MultiStep','Exponential', None]
decay                       : 0.1 #Learnng rate decay to apply (lr*decay)
sched_patience              : 5 # ReduceLROnPlateau option: epoch patience without loss change until a lr decrement
step_size                   : 20 #Step option: epoch counter to decrease lr
milestone                   : !!python/tuple [10] #MultiStep option: define different milestones (epochs) to decrease lr
    ### Save criteria
save_condition              : 'f1_score' # ['always','(x)_loss','(x)_mAcc','(x)_mIoU'] x : valid or train_loss
    ### Early Stopping
early_stopping              : False
stop_condition              : 'f1_score' # [(x)_loss','(x)_mAcc','(x)_mIoU'] x : valid or train_loss
patience                    : 5

# Image preprocess
rescale                     : 0.00392157
mean                        : !!python/tuple [127.5,127.5,127.5] #[104.00698793, 116.66876762, 122.67891434] #[103.939, 116.779, 123.68] #[0.28689553, 0.32513301, 0.28389176] #[0.37296272, 0.37296272, 0.37296272]
std                         : !!python/tuple [1.,1.,1.] #[0.18696375, 0.19017339, 0.18720214]#[0.21090189, 0.21090189, 0.21090189]

# Data augmentation
hflips                      : False
random_dist                 : False  # Activate random distortions to the input image [brightness, contrast, saturation]

color_map                   : null
num_images                  : null